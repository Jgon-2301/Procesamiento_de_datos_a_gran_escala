{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cef1a905-c867-4fdc-af90-cb109c91587b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Procesamiento de Datos a Gran Escala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da1e94d3-6388-4894-8be3-f83d075bbc4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pontificia Universidad Javeriana\n",
    "\n",
    "*Autor:*\n",
    "- Juan Felipe González Quintero \n",
    "\n",
    "*Fecha:* 29 - 10 - 2025\n",
    "\n",
    "---\n",
    "\n",
    "## **Temática**\n",
    "Técnicas de preprocesamiento de datos con Pyspark\n",
    "\n",
    "---\n",
    "\n",
    "## **Contexto**\n",
    "\n",
    "Preparar grandes volúmenes de datos es muy importante para su posterior uso en modelos de Machine Learning. \n",
    "\n",
    "En entornos reales (como empresas, bancos o sistemas de salud), los datos:\n",
    "\n",
    "* Provienen de múltiples fuentes,\n",
    "\n",
    "* Contienen valores nulos o inconsistentes,\n",
    "\n",
    "* Y suelen requerir transformaciones y limpieza antes de poder analizarlos o entrenar modelos predictivos.\n",
    "\n",
    "Por eso, PySpark —una librería distribuida sobre Apache Spark— resulta esencial, ya que permite manejar datasets de gran tamaño de manera eficiente, paralela y escalable.\n",
    "\n",
    "---\n",
    "\n",
    "## **Objetivo**\n",
    "El objetivo de este cuaderno es aprender sentencias pyspark para el preprocesamiento de los datos a través de ejemplos básicos de diferentes técnicas utilizadas en el medio.\n",
    "\n",
    "---\n",
    "\n",
    "## **Metodología**\n",
    "La metodología seguida en esta práctica se estructura en varias etapas orientadas al tratamiento de los datos mediante PySpark:\n",
    "\n",
    "* **Creación de un dataframe de prueba:** Para entender el flujo básico del preprocesamiento de una forma sencilla.\n",
    "\n",
    "* **Identificación y tratamiento de valores faltantes:** Se exploran distintas técnicas aplicables para el tratamiento de valores faltantes en los datos.\n",
    "\n",
    "* **Limpieza de datos:** se identifican y eliminan valores nulos o duplicados con funciones como dropna() y dropDuplicates().\n",
    "\n",
    "* **Pivoting y Explode:** Se hace uso de estas técnicas para reorganizar los datos de una forma más coherente.\n",
    "\n",
    "* **Normalización de datos:** Para obtener una mayor comprensión sobre los datos, se aplica normalización en algunas de las variables del estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4bf065-c418-48bc-baf0-e06f824a1560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Identificación y tratamiento de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e12a06c-a2b4-460d-9b83-28cdea95a767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "[\n",
    "('Store 1',1,448),\n",
    "('Store 1',2,None),\n",
    "('Store 1',3,499),\n",
    "('Store 1',44,432),\n",
    "(None,None,None),\n",
    "('Store 2',1,355),\n",
    "('Store 2',1,355),\n",
    "('Store 2',None,345),\n",
    "('Store 2',3,387),\n",
    "('Store 2',4,312),\n",
    "],\n",
    "['Store','WeekInMonth','Revenue']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35cae6e8-8b82-4dcb-8d5a-30ce2466ad72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Indentificación**\n",
    "A continuación se hace la identificación de valores nulos abarcando diferentes enfoques siendo estos:\n",
    "- Filtrar los valores nulos de una sola columna\n",
    "- Filtrar los valores nulos de todo el dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd109d17-ebb0-46fe-a827-dd34fffe6378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>2</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         2,
         null
        ],
        [
         null,
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#En este caso se hace el filtrado de valores nulos únicamente para la columna 'Revenue' y se imprimen por pantalla\n",
    "display(df.filter(df.Revenue.isNull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "112a18c3-a341-4d6b-85f1-f02ebf733c0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Como se pudo evidenciar, la función `filter()` en este caso retorna los registros del dataframe en los que el valor de la columna `Revenue`tiene por valor \"null\".\n",
    "\n",
    "Ahora, si se quisiera contar la cantidad de resitros nulos por cada una de las columnas, tendría que ejecutarse algo como lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64bafd13-1f7e-460c-9705-9047e254469f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         2,
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#En este caso, el filtrado se hace para todas las columnas a través de una consulta SQL, se cuenta la cantidad de registros nulos por cada una y posteriormente se imprimen por pantalla\n",
    "\n",
    "from pyspark.sql.functions import count, when, isnull\n",
    "display(df.select(\n",
    "[count(when(isnull(c), c)).alias(c) for c in df.columns]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bb98b04-7944-4e46-8cfd-fe7f7fc3f4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Tratamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26c4fcbd-0a63-4eb4-9b92-da860c962763",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Eliminado registros con valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c32b09fe-ad86-45e6-9945-032b9afa2d19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Para aplicar la eliminación de registros con valores faltantes, al igual que en el apartado anterior, se puede hacer de varias formas dependiendo el enfoque necesario.\n",
    "\n",
    "Un posible enfoque podría ser el que se presenta a continuación, donde a través de la función `dropna()` se hace la eliminación de **todos los registros que contengan, en cualquiera de las columnas, un valor nulo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35dab91b-ef8b-4125-ab17-79a1893a05cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se eliminan del dataframe todos los registros con algún valor nulo en cualquiera de las columnas que lo integran\n",
    "df2 = df.dropna()\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3225a19f-b063-4787-826b-c8f740e3c58e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Como se puede ver, al aplicar lo anterior ya no se muestran más aquellos registros que contenían uno o más valores nulos y en su lugar, se conservan en el dataframe todos los registros que si contenían información completa.\n",
    "\n",
    "Otro posible enfoque (según lo requiera el caso) podría ser el de eliminar únicamente los registros que contengan valores nulos en **todas sus columnas** como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37a4ad5-172d-4a08-aec4-be22a6d26da1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>null</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>null</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         null
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         null,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se hace la eliminación de los registros que contienen valores nulos en todas sus columnas con el argumento 'all' en la función dropna()\n",
    "df2 = df.dropna('all')\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "902789d0-2653-4e51-a76b-650b3525b033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Sustituyendo por un valor\n",
    "\n",
    "Otra posible alternativa para el tratamiento de datos nulos aparte de eliminarlos direcatamente, es reemplazarlos con otros valores. Esto se puede aplicar únicamente **dependiendo** de si tiene sentido conceptual aplicar estas sustituciones, ya que existen muchos casos en los cuáles si reemplazamos los nulos con otro valor, los datos pierden sentido e integridad, dando lugar a confusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb57d500-02f9-45ed-bcca-63c4d1b6444b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There is one important thing to note about fillna – it’ll only do the exchange\n",
    "operation for matching column types. So if you use a numeric value for a string column\n",
    "or the other way around, it won’t work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83d85063-5e49-4639-87a3-40a2a6232654",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Una posible forma de abordar este reemplazo es definiendo directamente un valor por el cuál serán reemplazados todos los valores nulos a través de la función `fillna()`. Algo importante a tener en cuenta es que esta función solo nos permite hacer el reemplazo **si el tipo de variable del valor que se le proporciona como argumento coincide con el de la columna**, es decir que por ejemplo, si se proporciona como argumento de `fillna()` un valor numérico, el reemplazo solo será efectuado en las columnas que sean de tipo numérico, de otra forma, no se aplicará.\n",
    "\n",
    "Para demostrar lo anteriormente explicado, a continuación se indica de tres formas distintas como se puede realizar el reemplazo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c1b1cf9-620a-4a54-bbde-a2a0028467a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>0</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>null</td><td>0</td><td>0</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>0</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         0
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         null,
         0,
         0
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         0,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>0</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>null</td><td>null</td><td>0</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>null</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         0
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         null,
         null,
         0
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         null,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>3</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>null</td><td>2</td><td>3</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>2</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         3
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         null,
         2,
         3
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         2,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se intenta hacer el reemplazo de TODOS los valores nulos del dataframe por 0\n",
    "display(df.fillna(0))\n",
    "\n",
    "#Se hace el reemplazo de los valores nulos de la columna 'Revenue' por 0\n",
    "display(df.fillna(0, ['Revenue']))\n",
    "\n",
    "#Se hace el reemplazo de los valores nulos de la columna 'WeekInMonth' por el número 2 y de la columna 'Revenue' por el número 3\n",
    "display(df.fillna({'WeekInMonth' : 2, 'Revenue' : 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9b83aee-56cf-416e-a4f6-f70e4f87c9fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "De los resultados obtenidos de la aplicación de la función `fillna()` sobre el dataframe se puede hacer mención de ciertos detalles:\n",
    "\n",
    "- Para el primer uso (el intento de reemplazar todos los valores nulos de todo el dataframe por 0), se puede notar a simple vista que el cambio fue efectuado en las columnas `WeekInMonth` y `Revenue` que poseen valores numéricos, pero en el caso de la columna `Store`, el reemplazo no surte efecto debido a que el tipo de variable de esta columna no coincide con el del valor por el cual se intentó reemplazar.\n",
    "- Para el segundo uso (el reemplazo de todos los valores nulos de la columna Revenue) se efectúa el reemplazo de todos los nulos por cero mientras las demás columnas mantienen sus valores nulos.\n",
    "- Para el último uso (reemplazo de todos los valores nulos de las columnas `WeekInMonth` y `Revenue`) se efectúa el cambio correctamente, mientras la columna restante mantiene sus valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a3348a6-fff5-4585-b41b-7a89d3eaa082",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###3. Sustituyendo con la media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c390619f-81f4-4df9-be3d-957e6811a9e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Otra forma de abordar el tratamiento de valores nulos es hacer la sustitución por la media. A esta técnica se le llama **imputación por la media** y consiste en reemplazar los valores nulos de una variable numérica por el promedio de los valores existentes en esa misma columna. **Tiene sentido aplicarla cuando los datos faltantes son pocos**, se asumen como aleatorios (es decir, no siguen un patrón sistemático) y la variable no presenta una gran dispersión ni valores atípicos que distorsionen la media. Es una estrategia simple y útil para mantener el tamaño del conjunto de datos sin introducir sesgos significativos.\n",
    "\n",
    "Para aplicar esta técnica, a continuación se hace el cálculo de la media para una de las columnas del dataframe y posteriormente se aplica el reemplazo con la función `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed18babf-ff07-4e78-88d3-cbd149bfbae7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|avg(Revenue)|\n+------------+\n|     391.625|\n+------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Se realiza el cálculo de la media para la columna Revenue a través de la funcón mean\n",
    "from pyspark.sql.functions import mean\n",
    "df.select(mean(df.Revenue)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be79d5e6-db26-4e80-86c0-f0d413b9c55a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Una vez calculado el valor promedio de la columna, se procede a realizar el reemplazo de los valores nulos por ese valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d031674-d2f2-4666-b815-7af946c378dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>391</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>null</td><td>null</td><td>391</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>null</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         391
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         null,
         null,
         391
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         null,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se realiza el reemplazo de los valores nulos de la columna 'Revenue' por la media de la columna\n",
    "display(df.fillna(391.625, ['Revenue']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dd98ae9-0d82-4173-be80-2fb012e23c1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Eliminando duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff56371f-d79e-401c-bc5e-6f160b1a57d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Otra técnica de preprocesamiento de datos es la eliminación de duplicados. En este caso es posible aplicar esta técnica a través de la función `dropDuplicates()` como se evidencia a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84c10108-ee0f-4f09-8d44-dfd6f6e63c17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>null</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>null</td><td>null</td><td>null</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>null</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         null
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         null,
         null,
         null
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         null,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Eliminación de registros duplicados\n",
    "display(df.dropDuplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6466a811-81d2-4362-8ce4-f6d5e3cf63c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En este caso se evidencia que en efecto se eliminó el único registro duplicado, el cuál tenía asociados los valores 'Store 2', '1', '355'.\n",
    "\n",
    "Otra forma de obtener el mismo resultado que se vió anteriormente es utilizar la función `dropDuplicates()` para eliminar los registros que tengan la misma combinación de valores en las columnas  `WeekInMonth` y `Revenue`, es decir, que existan 2 registros o más con los mismos valores exactamente en esas dos columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7c36493-cff2-4803-b219-61c24de03fc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>null</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>null</td><td>null</td><td>null</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>null</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         null
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         null,
         null,
         null
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         null,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.dropDuplicates(['Store','WeekInMonth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb557633-dd91-44a7-bdee-997f07fe70fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En este caso, también se eliminó el registro del cuál ya se había hecho mención antes ya que con la función se detectaron dos registros con exactamente el valor '1' en la columna  `WeekInMonth` y  el valor '355' en la columna `Revenue`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d78a2e1a-32f4-4d17-9434-8957f48fdd81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Eliminando columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b27ab9f-7d1b-4b4b-b784-d27a83d51260",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Así como es posible eliminar registros, también existe otra técnica de preprocesamiento de datos que permite eliminar columnas (bien puede ser que no son relevantes para el estudio, poseen una cantidad considerable de registros nulos, etc).\n",
    "\n",
    "A continuación se aplica esta técnica a través del uso de la función `drop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e147ede5-8610-403c-a229-8a505bdba71a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td></tr><tr><td>Store 1</td><td>2</td></tr><tr><td>Store 1</td><td>3</td></tr><tr><td>Store 1</td><td>44</td></tr><tr><td>null</td><td>null</td></tr><tr><td>Store 2</td><td>1</td></tr><tr><td>Store 2</td><td>1</td></tr><tr><td>Store 2</td><td>null</td></tr><tr><td>Store 2</td><td>3</td></tr><tr><td>Store 2</td><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1
        ],
        [
         "Store 1",
         2
        ],
        [
         "Store 1",
         3
        ],
        [
         "Store 1",
         44
        ],
        [
         null,
         null
        ],
        [
         "Store 2",
         1
        ],
        [
         "Store 2",
         1
        ],
        [
         "Store 2",
         null
        ],
        [
         "Store 2",
         3
        ],
        [
         "Store 2",
         4
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>WeekInMonth</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>44</td></tr><tr><td>null</td></tr><tr><td>1</td></tr><tr><td>1</td></tr><tr><td>null</td></tr><tr><td>3</td></tr><tr><td>4</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ],
        [
         2
        ],
        [
         3
        ],
        [
         44
        ],
        [
         null
        ],
        [
         1
        ],
        [
         1
        ],
        [
         null
        ],
        [
         3
        ],
        [
         4
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se elimina la columna 'Revenue'\n",
    "display(df.drop('Revenue'))\n",
    "\n",
    "#Se eliminan las columnas 'Revenue' y 'Store'\n",
    "display(df.drop('Revenue','Store'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "246ae203-4784-4866-ab25-a7f56eca2153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En este caso se ejemplifica la eliminación de columnas con una sola eliminación y dos eliminaciones, las cuáles se efectuaron correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6647c35-1b99-450b-881f-10e39a478438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Identificando y resolviendo valores inconsistentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e897f44-a800-437a-bb1c-a9c56363bea3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Una técnica más de preprocesamiento de datos es la detectacción y evaluación de valores inconsistentes o atípicos en los datos (por ejemplo, valores numéricos negativos o desproporcionadamente altos).\n",
    "Una vez identificados, el siguiente paso suele ser corregirlos, eliminarlos o imputarlos según la naturaleza del análisis.\n",
    "\n",
    "A continuación se ve un ejemplo de como podría aplicarse esta técnica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6957f8e0-30f6-4bd2-80e4-922a7cfa45e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 1</td><td>2</td><td>null</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr><tr><td>null</td><td>null</td><td>null</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>1</td><td>355</td></tr><tr><td>Store 2</td><td>null</td><td>345</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 1",
         2,
         null
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 1",
         44,
         432
        ],
        [
         null,
         null,
         null
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         1,
         355
        ],
        [
         "Store 2",
         null,
         345
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se revisan los valores de los registros del dataframe\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36520c1d-1eec-48b8-8adc-19a54684f4e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Luego de revisar los datos contenidos en el dataframe, se puede hacer un análisis descriptivo de cierto grupo de registros específico en busca de valores atípicos. Para este ejemplo se hace sobre la columna Store y el grupo de registros cuyo valor en esa columna es Store 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af3f9ec-b888-44c2-9225-cd2d3fe8d332",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>summary</th><th>Store</th><th>WeekInMonth</th><th>Revenue</th></tr></thead><tbody><tr><td>count</td><td>4</td><td>4</td><td>3</td></tr><tr><td>mean</td><td>null</td><td>12.5</td><td>459.6666666666667</td></tr><tr><td>stddev</td><td>null</td><td>21.01586702153082</td><td>34.99047489436709</td></tr><tr><td>min</td><td>Store 1</td><td>1</td><td>432</td></tr><tr><td>max</td><td>Store 1</td><td>44</td><td>499</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "count",
         "4",
         "4",
         "3"
        ],
        [
         "mean",
         null,
         "12.5",
         "459.6666666666667"
        ],
        [
         "stddev",
         null,
         "21.01586702153082",
         "34.99047489436709"
        ],
        [
         "min",
         "Store 1",
         "1",
         "432"
        ],
        [
         "max",
         "Store 1",
         "44",
         "499"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "summary",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se filtra los registros que contienen el valor 'Store 1' en la columna 'Store' y se realiza un análisis descriptivo de los mismos\n",
    "display(df.filter(df.Store == 'Store 1').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4249107-5cca-4a9f-9d4a-6f58ef24c11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Esto dará el valor en un cuantil dado, en el intervalo de 0 a 1. Por lo tanto, si establece el segundo argumento en 0.0, obtendrá el valor más bajo para la columna. Con 1.0 obtienes el valor más alto. En el medio tienes la mediana, que es lo que se está buscando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3796b01b-4ec2-42cf-b6dd-de6d2b2771a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[355.0]\n"
     ]
    }
   ],
   "source": [
    "print(df.approxQuantile('Revenue', [0.5], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c9055f-a2c0-4699-ae26-7b00d9402a4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b50e7857-b5cc-4e59-ba82-be21e8bbdc7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A veces, desea cambiar sus datos de filas a columnas. La función se llama pivotar y está disponible en Pyspark.\n",
    "\n",
    "Básicamente, estás rotando los datos alrededor de un eje determinado, de ahí el nombre.\n",
    "\n",
    "En este caso, ese eje son los datos en una de sus columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02d66290-aad9-45aa-aeba-e38eeef83e42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Para ejemplificar esto, se realizará un pivotado sobre el DataFrame original para que las tiendas (Store) se conviertan en columnas y las semanas del mes (WeekInMonth) en filas.\n",
    "\n",
    "De esta manera, los ingresos (Revenue) se agregan y reorganizan por tienda y semana, obteniendo una estructura más adecuada para el análisis y visualización de patrones de venta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d036bb2-7a46-4314-a020-30e14b8292ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>WeekInMonth</th><th>null</th><th>Store 1</th><th>Store 2</th></tr></thead><tbody><tr><td>null</td><td>null</td><td>null</td><td>345</td></tr><tr><td>1</td><td>null</td><td>448</td><td>710</td></tr><tr><td>2</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3</td><td>null</td><td>499</td><td>387</td></tr><tr><td>4</td><td>null</td><td>null</td><td>312</td></tr><tr><td>44</td><td>null</td><td>432</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         null,
         null,
         null,
         345
        ],
        [
         1,
         null,
         448,
         710
        ],
        [
         2,
         null,
         null,
         null
        ],
        [
         3,
         null,
         499,
         387
        ],
        [
         4,
         null,
         null,
         312
        ],
        [
         44,
         null,
         432,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "null",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Store 1",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Store 2",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Se realizan agregaciones por medio de la función groupBy y pivot para obtener el total de ventas por semana\n",
    "df_pivoted = df.groupBy('WeekInMonth').pivot('Store').sum('Revenue').orderBy('WeekInMonth')\n",
    "display(df_pivoted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d8be883-fcc2-4e56-b8b6-c3a97c17494a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Posteriormente se realiza una consulta de agregación que tambien agrupa por pivote y WeekInMonth y luego suma el revenue. Esto se hace con el objetivo de comparar las agregaciones solas, con el pivote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2305634-8244-4cfb-98cf-fdb6bb6f5e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Store</th><th>WeekInMonth</th><th>sum(Revenue)</th></tr></thead><tbody><tr><td>null</td><td>null</td><td>null</td></tr><tr><td>Store 2</td><td>null</td><td>345</td></tr><tr><td>Store 1</td><td>1</td><td>448</td></tr><tr><td>Store 2</td><td>1</td><td>710</td></tr><tr><td>Store 1</td><td>2</td><td>null</td></tr><tr><td>Store 1</td><td>3</td><td>499</td></tr><tr><td>Store 2</td><td>3</td><td>387</td></tr><tr><td>Store 2</td><td>4</td><td>312</td></tr><tr><td>Store 1</td><td>44</td><td>432</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         null,
         null,
         null
        ],
        [
         "Store 2",
         null,
         345
        ],
        [
         "Store 1",
         1,
         448
        ],
        [
         "Store 2",
         1,
         710
        ],
        [
         "Store 1",
         2,
         null
        ],
        [
         "Store 1",
         3,
         499
        ],
        [
         "Store 2",
         3,
         387
        ],
        [
         "Store 2",
         4,
         312
        ],
        [
         "Store 1",
         44,
         432
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{\"__autoGeneratedAlias\": \"true\"}",
         "name": "sum(Revenue)",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df\n",
    ".groupBy('Store','WeekInMonth')\n",
    ".sum('Revenue')\n",
    ".orderBy('WeekInMonth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb52a121-cbe1-4a87-9adb-f39363e53bcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Como se puede observar en las tablas resultantes, tanto la agregación como el pivotado se basan en el mismo principio de agrupar y resumir datos, pero sus objetivos son diferentes:\n",
    "\n",
    "- Al utilizar únicamente la **agregación**, se obtiene el revenue total por tienda y semana, pero la estructura de la tabla permanece en formato vertical, lo que dificulta identificar patrones o realizar comparaciones directas entre tiendas.  \n",
    "- En cambio, con el **pivotado**, los datos se reorganizan en un formato horizontal, permitiendo observar de forma más clara el comportamiento del revenue de cada tienda por semana, facilitando el análisis visual y la detección de tendencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d8eecdc-0e94-48ac-9a71-ef27fcbdd359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Adicionalmente, se puede aplicar la operación inversa al pivotado, conocida como unpivot o stack.  \n",
    "Este proceso convierte las columnas generadas por el pivote en filas, devolviendo los datos a un formato vertical.  \n",
    "\n",
    "En este caso la función stack() permite reorganizar los valores de las columnas de cada tienda en un solo atributo común llamado Store, con su respectivo Revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfa655b-bc27-4183-b4f0-69ef33148a28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>WeekInMonth</th><th>Store</th><th>Revenue</th></tr></thead><tbody><tr><td>null</td><td>Store 1</td><td>null</td></tr><tr><td>null</td><td>Store 2</td><td>345</td></tr><tr><td>1</td><td>Store 1</td><td>448</td></tr><tr><td>1</td><td>Store 2</td><td>710</td></tr><tr><td>2</td><td>Store 1</td><td>null</td></tr><tr><td>2</td><td>Store 2</td><td>null</td></tr><tr><td>3</td><td>Store 1</td><td>499</td></tr><tr><td>3</td><td>Store 2</td><td>387</td></tr><tr><td>4</td><td>Store 1</td><td>null</td></tr><tr><td>4</td><td>Store 2</td><td>312</td></tr><tr><td>44</td><td>Store 1</td><td>432</td></tr><tr><td>44</td><td>Store 2</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         null,
         "Store 1",
         null
        ],
        [
         null,
         "Store 2",
         345
        ],
        [
         1,
         "Store 1",
         448
        ],
        [
         1,
         "Store 2",
         710
        ],
        [
         2,
         "Store 1",
         null
        ],
        [
         2,
         "Store 2",
         null
        ],
        [
         3,
         "Store 1",
         499
        ],
        [
         3,
         "Store 2",
         387
        ],
        [
         4,
         "Store 1",
         null
        ],
        [
         4,
         "Store 2",
         312
        ],
        [
         44,
         "Store 1",
         432
        ],
        [
         44,
         "Store 2",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "WeekInMonth",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Store",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Revenue",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_pivoted.withColumnRenamed('Store 1','Store1')\n",
    "        .withColumnRenamed('Store 2','Store2')\n",
    "        .selectExpr('WeekInMonth',\"stack(2, 'Store 1', Store1, 'Store 2', Store2) as (Store,Revenue)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c05926e7-8eaf-4983-8b70-f6f104b51bb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce3036a5-f047-4f4f-88b2-9d157f129f0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Hay otra situación con la que te encontrarás de vez en cuando. A veces llegan varios puntos de datos juntos en una columna. Esto usual cuando JSON es el formato de origen.\n",
    "\n",
    "Puede resolver este problema utilizando el comando de Explode. Tomará la cadena con varios valores y los colocará en una fila cada uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b5811ba-f02b-4749-b56d-3020b35a2879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Para ejemplificar esto, se crea un dataframe en el que se tiene una columan que tiene como datos listas de relojes.\n",
    "\n",
    "Al usar explode cada elemento de la lista watches se convierte en una fila independiente, lo que facilita análisis posteriores como conteos, agrupaciones o cálculos estadísticos por tipo de reloj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aedb651e-20c6-4e59-9d04-6a997ff47e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>watches</th></tr></thead><tbody><tr><td>1</td><td>Rolex</td></tr><tr><td>1</td><td>Patek</td></tr><tr><td>1</td><td>Jaeger</td></tr><tr><td>2</td><td>Omega</td></tr><tr><td>2</td><td>Heuer</td></tr><tr><td>3</td><td>Swatch</td></tr><tr><td>3</td><td>Rolex</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Rolex"
        ],
        [
         1,
         "Patek"
        ],
        [
         1,
         "Jaeger"
        ],
        [
         2,
         "Omega"
        ],
        [
         2,
         "Heuer"
        ],
        [
         3,
         "Swatch"
        ],
        [
         3,
         "Rolex"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "watches",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df = spark.createDataFrame([\n",
    "(1, ['Rolex','Patek','Jaeger']),\n",
    "(2, ['Omega','Heuer']),\n",
    "(3, ['Swatch','Rolex'])],\n",
    "('id','watches'))\n",
    "display(df.withColumn('watches',explode(df.watches)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc2c23b0-025b-453e-9305-52d2af100b71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Normalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ad0bdfa-bf14-4065-b0cb-0c319c0b71cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Antes de aplicar las técnicas de **normalización**, es necesario verificar la existencia del conjunto de datos que se va a utilizar.  \n",
    "El comando `%fs ls` lista los archivos disponibles en la ruta especificada dentro del sistema de archivos de Databricks (DBFS), en este caso `/databricks-datasets/definitive-guide/data/simple-ml-scaling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26807964-8824-472d-b73e-0b31dc0150dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/definitive-guide/data/simple-ml-scaling/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1596560320000</td></tr><tr><td>dbfs:/databricks-datasets/definitive-guide/data/simple-ml-scaling/part-00000-cd03406a-cc9b-42b0-9299-1e259fdd9382-c000.gz.parquet</td><td>part-00000-cd03406a-cc9b-42b0-9299-1e259fdd9382-c000.gz.parquet</td><td>1663</td><td>1596560320000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/definitive-guide/data/simple-ml-scaling/_SUCCESS",
         "_SUCCESS",
         0,
         1596560320000
        ],
        [
         "dbfs:/databricks-datasets/definitive-guide/data/simple-ml-scaling/part-00000-cd03406a-cc9b-42b0-9299-1e259fdd9382-c000.gz.parquet",
         "part-00000-cd03406a-cc9b-42b0-9299-1e259fdd9382-c000.gz.parquet",
         1663,
         1596560320000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /databricks-datasets/definitive-guide/data/simple-ml-scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23fead71-bf06-4905-a720-5e5e77a23a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Una vez verificada la disponibilidad del conjunto de datos, se procede con su carga utilizando el formato `parquet`.  \n",
    "El comando `spark.read.parquet()` permite leer archivos almacenados en este formato optimizado, generando un DataFrame distribuido en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e7a203b-0bb1-4eb1-b673-93fe9be10094",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>features</th></tr></thead><tbody><tr><td>0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"1.0\",\"0.1\",\"-1.0\"]}</td></tr><tr><td>1</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"2.0\",\"1.1\",\"1.0\"]}</td></tr><tr><td>0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"1.0\",\"0.1\",\"-1.0\"]}</td></tr><tr><td>1</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"2.0\",\"1.1\",\"1.0\"]}</td></tr><tr><td>1</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"3.0\",\"10.1\",\"3.0\"]}</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"1.0\",\"0.1\",\"-1.0\"]}"
        ],
        [
         1,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"2.0\",\"1.1\",\"1.0\"]}"
        ],
        [
         0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"1.0\",\"0.1\",\"-1.0\"]}"
        ],
        [
         1,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"2.0\",\"1.1\",\"1.0\"]}"
        ],
        [
         1,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"3.0\",\"10.1\",\"3.0\"]}"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "features",
         "type": "{\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"fields\":[{\"metadata\":{},\"name\":\"type\",\"nullable\":false,\"type\":\"byte\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"indices\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"integer\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"values\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"double\",\"type\":\"array\"}}],\"type\":\"struct\"},\"type\":\"udt\"}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaleDF = spark.read.parquet(\"/databricks-datasets/definitive-guide/data/simple-ml-scaling\")\n",
    "display(scaleDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e1f1d74-6cd7-42f6-afbd-635d59e98922",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ahora se procede a realizar la normalización de escala Min–Max, una técnica que ajusta los valores numéricos de una característica a un nuevo rango definido.  \n",
    "La función `MinMaxScaler` de MLlib calcula los valores mínimo y máximo del conjunto y reescala cada valor proporcionalmente dentro del intervalo definido mediante `setMin()` y `setMax()` (en este caso [5, 10])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bac4159-eff2-4c59-85b4-34dba941e16f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+---------------------------------+\n| id|      features|MinMaxScaler_e51f876d3730__output|\n+---+--------------+---------------------------------+\n|  0|[1.0,0.1,-1.0]|                    [5.0,5.0,5.0]|\n|  1| [2.0,1.1,1.0]|                    [7.5,5.5,7.5]|\n|  0|[1.0,0.1,-1.0]|                    [5.0,5.0,5.0]|\n|  1| [2.0,1.1,1.0]|                    [7.5,5.5,7.5]|\n|  1|[3.0,10.1,3.0]|                 [10.0,10.0,10.0]|\n+---+--------------+---------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "minMax = MinMaxScaler().setMin(5).setMax(10).setInputCol(\"features\")\n",
    "fittedminMax = minMax.fit(scaleDF)\n",
    "fittedminMax.transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "101f9ea8-8949-48a7-9118-572972e0787d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ahora, se cambia la normalización por **normalización estadística** o **estandarización Z-Score**, utilizando el transformador `StandardScaler` de MLlib.  \n",
    "\n",
    "Esta técnica ajusta los datos restando la media y dividiendo por la desviación estándar de cada atributo, de forma que los valores finales tengan media igual a 0 y varianza unitaria (desviación estándar igual a 1).\n",
    "\n",
    "A diferencia del escalado Min–Max, este método no define un rango fijo, sino que centra los datos y los escala estadísticamente para que todas las variables tengan la misma magnitud relativa.  \n",
    "\n",
    "De esta manera, se reduce el efecto de las diferentes escalas y unidades de medida entre atributos, aunque no elimina completamente la influencia de los valores atípicos, ya que estos aún afectan el cálculo de la media y la desviación estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4ff1b4e-49b0-4267-a936-bda25a3649dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----------------------------------+\n| id|      features|StandardScaler_0cb5e52fc5c7__output|\n+---+--------------+-----------------------------------+\n|  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n|  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n|  0|[1.0,0.1,-1.0]|               [1.19522860933439...|\n|  1| [2.0,1.1,1.0]|               [2.39045721866878...|\n|  1|[3.0,10.1,3.0]|               [3.58568582800318...|\n+---+--------------+-----------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "sScaler = StandardScaler().setInputCol(\"features\")\n",
    "sScaler.fit(scaleDF).transform(scaleDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d964541-c3d5-4e9e-91e0-fe978dea6cd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Conclusiones\n",
    "\n",
    "- El preprocesamiento de datos es una fase crítica en cualquier proyecto de Machine Learning, ya que garantiza la calidad, consistencia y coherencia de la información antes de su análisis o modelado. Sin una limpieza adecuada, los resultados de los modelos pueden ser imprecisos o incluso erróneos.\n",
    "\n",
    "- El uso de PySpark facilita el manejo de grandes volúmenes de datos gracias a su procesamiento distribuido, permitiendo realizar operaciones de limpieza, transformación y análisis de forma paralela, eficiente y escalable dentro de entornos como Databricks.\n",
    "\n",
    "- Las funciones dropna() y dropDuplicates() resultan fundamentales para la eliminación de valores nulos y duplicados, mientras que métodos como filter() y approxQuantile() permiten identificar valores inconsistentes y analizar la distribución de los datos.\n",
    "\n",
    "- El tratamiento de valores inconsistentes mediante estadísticas descriptivas y cuantiles contribuye a detectar posibles outliers o errores en los registros, lo que asegura una mayor confiabilidad en el conjunto final de datos utilizado para el modelado.\n",
    "\n",
    "- La práctica permitió comprender el flujo completo de preparación de datos en PySpark, desde la importación y exploración inicial hasta la limpieza, transformación y validación final, consolidando así los fundamentos para aplicar técnicas de análisis y aprendizaje automático sobre datos reales a gran escala."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5921891333529667,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ML_Preprocesamiento_González",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}